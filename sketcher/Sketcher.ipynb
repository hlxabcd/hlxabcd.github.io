{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sketcher.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hlxabcd/hlxabcd.github.io/blob/master/sketcher/Sketcher.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "zlx6-LFL_jbi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This file contains a subset of the quick draw classes. I choose around 100 classes from the dataset. "
      ]
    },
    {
      "metadata": {
        "id": "6H3ATAdp_URp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Get the Class names "
      ]
    },
    {
      "metadata": {
        "id": "XXv-xzU1sd88",
        "colab_type": "code",
        "outputId": "a3270482-73c5-4730-a6ae-feaa00100bdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "cell_type": "code",
      "source": [
        "!wget 'https://raw.githubusercontent.com/hlxabcd/hlxabcd.github.io/master/sketcher/class_names.txt'"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-19 11:33:59--  https://raw.githubusercontent.com/hlxabcd/hlxabcd.github.io/master/sketcher/class_names.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2790 (2.7K) [text/plain]\n",
            "Saving to: ‘class_names.txt.3’\n",
            "\n",
            "\rclass_names.txt.3     0%[                    ]       0  --.-KB/s               \rclass_names.txt.3   100%[===================>]   2.72K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-03-19 11:33:59 (62.7 MB/s) - ‘class_names.txt.3’ saved [2790/2790]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4GL_TdMffD6-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Read the classes names "
      ]
    },
    {
      "metadata": {
        "id": "eP-OxOx5sy0b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f = open(\"class_names.txt\",\"r\")\n",
        "# And for reading use\n",
        "classes = f.readlines()\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lTE6D3uxtMc5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classes = [c.replace('\\n','').replace(' ','_') for c in classes]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5NDfBHVjACAt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Download the Dataset "
      ]
    },
    {
      "metadata": {
        "id": "7MC_PUS-fKjH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Loop over the classes and download the currospondent data"
      ]
    },
    {
      "metadata": {
        "id": "rdSUnpL0u22Q",
        "colab_type": "code",
        "outputId": "bf89d64f-40b0-4442-d983-688d26e1fe27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir data"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "22DPhL5FtWcQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import os\n",
        "def download():\n",
        "  \n",
        "  base = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/'\n",
        "  for c in classes:\n",
        "    cls_url = c.replace('_', '%20')\n",
        "    if not os.path.exists('data/' + c + '.npy'):\n",
        "        path = base+cls_url+'.npy'\n",
        "        print(path)\n",
        "        urllib.request.urlretrieve(path, 'data/'+c+'.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O5jF6TXXu-Bu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "download() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uEdnbBVXAI-X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Imports "
      ]
    },
    {
      "metadata": {
        "id": "J2FYrPgOKh6t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras \n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rxgNFjNM5sWj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 分割npy库提高加载效率"
      ]
    },
    {
      "metadata": {
        "id": "SisxobWa54B-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def split_dataset(root,target,max_items_per_class= 1000 ):\n",
        "     all_files = glob.glob(os.path.join(root, '*.npy'))\n",
        "     for idx, file in enumerate(all_files):\n",
        "        print(\"process npy:\",idx,file)\n",
        "        data = np.load(file)\n",
        "        # npy长度\n",
        "        dataset_len = len(data)\n",
        "        start = 0\n",
        "        end = max_items_per_class\n",
        "        num = 1\n",
        "        fileName = file.split('/')[1].split('.')[0]\n",
        "        # 按max_items_per_class分割npy文件\n",
        "        while (start < dataset_len):\n",
        "            resultData = data[start: end, :]\n",
        "            # 分割后的文件命名\n",
        "            targetFile = os.path.join(target, fileName+str(num)+'.npy');\n",
        "            if not os.path.exists(targetFile):\n",
        "              np.save(targetFile, resultData)\n",
        "            num+=1\n",
        "            start+=max_items_per_class\n",
        "            end+=max_items_per_class\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CbXnUx_z90Iw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6245
        },
        "outputId": "a73aab1c-7064-41f4-ae0b-16df9a1bfb79"
      },
      "cell_type": "code",
      "source": [
        "# 分割npy\n",
        "!mkdir data_process\n",
        "split_dataset('data','data_process')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘data_process’: File exists\n",
            "process npy: 0 data/hot_tub.npy\n",
            "process npy: 1 data/underwear.npy\n",
            "process npy: 2 data/flashlight.npy\n",
            "process npy: 3 data/ice_cream.npy\n",
            "process npy: 4 data/watermelon.npy\n",
            "process npy: 5 data/shovel.npy\n",
            "process npy: 6 data/passport.npy\n",
            "process npy: 7 data/necklace.npy\n",
            "process npy: 8 data/train.npy\n",
            "process npy: 9 data/bathtub.npy\n",
            "process npy: 10 data/square.npy\n",
            "process npy: 11 data/baseball_bat.npy\n",
            "process npy: 12 data/panda.npy\n",
            "process npy: 13 data/spreadsheet.npy\n",
            "process npy: 14 data/floor_lamp.npy\n",
            "process npy: 15 data/ocean.npy\n",
            "process npy: 16 data/scorpion.npy\n",
            "process npy: 17 data/skull.npy\n",
            "process npy: 18 data/toilet.npy\n",
            "process npy: 19 data/cat.npy\n",
            "process npy: 20 data/hexagon.npy\n",
            "process npy: 21 data/elephant.npy\n",
            "process npy: 22 data/helmet.npy\n",
            "process npy: 23 data/pickup_truck.npy\n",
            "process npy: 24 data/grapes.npy\n",
            "process npy: 25 data/broccoli.npy\n",
            "process npy: 26 data/traffic_light.npy\n",
            "process npy: 27 data/garden_hose.npy\n",
            "process npy: 28 data/teapot.npy\n",
            "process npy: 29 data/pond.npy\n",
            "process npy: 30 data/flying_saucer.npy\n",
            "process npy: 31 data/rhinoceros.npy\n",
            "process npy: 32 data/barn.npy\n",
            "process npy: 33 data/television.npy\n",
            "process npy: 34 data/microphone.npy\n",
            "process npy: 35 data/alarm_clock.npy\n",
            "process npy: 36 data/candle.npy\n",
            "process npy: 37 data/monkey.npy\n",
            "process npy: 38 data/flower.npy\n",
            "process npy: 39 data/knee.npy\n",
            "process npy: 40 data/peanut.npy\n",
            "process npy: 41 data/squiggle.npy\n",
            "process npy: 42 data/sheep.npy\n",
            "process npy: 43 data/feather.npy\n",
            "process npy: 44 data/line.npy\n",
            "process npy: 45 data/river.npy\n",
            "process npy: 46 data/basketball.npy\n",
            "process npy: 47 data/stairs.npy\n",
            "process npy: 48 data/stove.npy\n",
            "process npy: 49 data/washing_machine.npy\n",
            "process npy: 50 data/ant.npy\n",
            "process npy: 51 data/vase.npy\n",
            "process npy: 52 data/fireplace.npy\n",
            "process npy: 53 data/marker.npy\n",
            "process npy: 54 data/fire_hydrant.npy\n",
            "process npy: 55 data/cannon.npy\n",
            "process npy: 56 data/canoe.npy\n",
            "process npy: 57 data/tree.npy\n",
            "process npy: 58 data/chair.npy\n",
            "process npy: 59 data/duck.npy\n",
            "process npy: 60 data/chandelier.npy\n",
            "process npy: 61 data/jail.npy\n",
            "process npy: 62 data/bus.npy\n",
            "process npy: 63 data/teddy-bear.npy\n",
            "process npy: 64 data/eye.npy\n",
            "process npy: 65 data/octopus.npy\n",
            "process npy: 66 data/mosquito.npy\n",
            "process npy: 67 data/cookie.npy\n",
            "process npy: 68 data/harp.npy\n",
            "process npy: 69 data/suitcase.npy\n",
            "process npy: 70 data/rake.npy\n",
            "process npy: 71 data/crocodile.npy\n",
            "process npy: 72 data/paintbrush.npy\n",
            "process npy: 73 data/lion.npy\n",
            "process npy: 74 data/bee.npy\n",
            "process npy: 75 data/laptop.npy\n",
            "process npy: 76 data/toothpaste.npy\n",
            "process npy: 77 data/sun.npy\n",
            "process npy: 78 data/speedboat.npy\n",
            "process npy: 79 data/hockey_stick.npy\n",
            "process npy: 80 data/beach.npy\n",
            "process npy: 81 data/truck.npy\n",
            "process npy: 82 data/leaf.npy\n",
            "process npy: 83 data/grass.npy\n",
            "process npy: 84 data/paint_can.npy\n",
            "process npy: 85 data/book.npy\n",
            "process npy: 86 data/hammer.npy\n",
            "process npy: 87 data/wine_bottle.npy\n",
            "process npy: 88 data/bear.npy\n",
            "process npy: 89 data/crab.npy\n",
            "process npy: 90 data/wheel.npy\n",
            "process npy: 91 data/t-shirt.npy\n",
            "process npy: 92 data/shoe.npy\n",
            "process npy: 93 data/see_saw.npy\n",
            "process npy: 94 data/fan.npy\n",
            "process npy: 95 data/star.npy\n",
            "process npy: 96 data/bench.npy\n",
            "process npy: 97 data/cake.npy\n",
            "process npy: 98 data/whale.npy\n",
            "process npy: 99 data/strawberry.npy\n",
            "process npy: 100 data/nail.npy\n",
            "process npy: 101 data/scissors.npy\n",
            "process npy: 102 data/raccoon.npy\n",
            "process npy: 103 data/car.npy\n",
            "process npy: 104 data/camel.npy\n",
            "process npy: 105 data/coffee_cup.npy\n",
            "process npy: 106 data/police_car.npy\n",
            "process npy: 107 data/power_outlet.npy\n",
            "process npy: 108 data/anvil.npy\n",
            "process npy: 109 data/flip_flops.npy\n",
            "process npy: 110 data/carrot.npy\n",
            "process npy: 111 data/mermaid.npy\n",
            "process npy: 112 data/soccer_ball.npy\n",
            "process npy: 113 data/string_bean.npy\n",
            "process npy: 114 data/The_Eiffel_Tower.npy\n",
            "process npy: 115 data/envelope.npy\n",
            "process npy: 116 data/oven.npy\n",
            "process npy: 117 data/bridge.npy\n",
            "process npy: 118 data/lipstick.npy\n",
            "process npy: 119 data/circle.npy\n",
            "process npy: 120 data/tornado.npy\n",
            "process npy: 121 data/diving_board.npy\n",
            "process npy: 122 data/piano.npy\n",
            "process npy: 123 data/rabbit.npy\n",
            "process npy: 124 data/zigzag.npy\n",
            "process npy: 125 data/crayon.npy\n",
            "process npy: 126 data/swing_set.npy\n",
            "process npy: 127 data/fork.npy\n",
            "process npy: 128 data/lighter.npy\n",
            "process npy: 129 data/lantern.npy\n",
            "process npy: 130 data/syringe.npy\n",
            "process npy: 131 data/hurricane.npy\n",
            "process npy: 132 data/rifle.npy\n",
            "process npy: 133 data/pliers.npy\n",
            "process npy: 134 data/bandage.npy\n",
            "process npy: 135 data/table.npy\n",
            "process npy: 136 data/triangle.npy\n",
            "process npy: 137 data/airplane.npy\n",
            "process npy: 138 data/drums.npy\n",
            "process npy: 139 data/bat.npy\n",
            "process npy: 140 data/firetruck.npy\n",
            "process npy: 141 data/pizza.npy\n",
            "process npy: 142 data/eyeglasses.npy\n",
            "process npy: 143 data/mountain.npy\n",
            "process npy: 144 data/bush.npy\n",
            "process npy: 145 data/zebra.npy\n",
            "process npy: 146 data/toaster.npy\n",
            "process npy: 147 data/postcard.npy\n",
            "process npy: 148 data/radio.npy\n",
            "process npy: 149 data/streetlight.npy\n",
            "process npy: 150 data/octagon.npy\n",
            "process npy: 151 data/telephone.npy\n",
            "process npy: 152 data/submarine.npy\n",
            "process npy: 153 data/lollipop.npy\n",
            "process npy: 154 data/popsicle.npy\n",
            "process npy: 155 data/stethoscope.npy\n",
            "process npy: 156 data/pants.npy\n",
            "process npy: 157 data/ambulance.npy\n",
            "process npy: 158 data/sleeping_bag.npy\n",
            "process npy: 159 data/birthday_cake.npy\n",
            "process npy: 160 data/fence.npy\n",
            "process npy: 161 data/pineapple.npy\n",
            "process npy: 162 data/pear.npy\n",
            "process npy: 163 data/dresser.npy\n",
            "process npy: 164 data/door.npy\n",
            "process npy: 165 data/asparagus.npy\n",
            "process npy: 166 data/animal_migration.npy\n",
            "process npy: 167 data/computer.npy\n",
            "process npy: 168 data/hot_dog.npy\n",
            "process npy: 169 data/guitar.npy\n",
            "process npy: 170 data/dragon.npy\n",
            "process npy: 171 data/arm.npy\n",
            "process npy: 172 data/hospital.npy\n",
            "process npy: 173 data/axe.npy\n",
            "process npy: 174 data/palm_tree.npy\n",
            "process npy: 175 data/foot.npy\n",
            "process npy: 176 data/owl.npy\n",
            "process npy: 177 data/bowtie.npy\n",
            "process npy: 178 data/hockey_puck.npy\n",
            "process npy: 179 data/pool.npy\n",
            "process npy: 180 data/horse.npy\n",
            "process npy: 181 data/wine_glass.npy\n",
            "process npy: 182 data/hourglass.npy\n",
            "process npy: 183 data/eraser.npy\n",
            "process npy: 184 data/house.npy\n",
            "process npy: 185 data/dishwasher.npy\n",
            "process npy: 186 data/mailbox.npy\n",
            "process npy: 187 data/skateboard.npy\n",
            "process npy: 188 data/tractor.npy\n",
            "process npy: 189 data/nose.npy\n",
            "process npy: 190 data/binoculars.npy\n",
            "process npy: 191 data/matches.npy\n",
            "process npy: 192 data/calculator.npy\n",
            "process npy: 193 data/The_Great_Wall_of_China.npy\n",
            "process npy: 194 data/dolphin.npy\n",
            "process npy: 195 data/diamond.npy\n",
            "process npy: 196 data/frying_pan.npy\n",
            "process npy: 197 data/mouse.npy\n",
            "process npy: 198 data/golf_club.npy\n",
            "process npy: 199 data/butterfly.npy\n",
            "process npy: 200 data/parachute.npy\n",
            "process npy: 201 data/tent.npy\n",
            "process npy: 202 data/cup.npy\n",
            "process npy: 203 data/van.npy\n",
            "process npy: 204 data/trumpet.npy\n",
            "process npy: 205 data/backpack.npy\n",
            "process npy: 206 data/helicopter.npy\n",
            "process npy: 207 data/hot_air_balloon.npy\n",
            "process npy: 208 data/roller_coaster.npy\n",
            "process npy: 209 data/tooth.npy\n",
            "process npy: 210 data/hand.npy\n",
            "process npy: 211 data/angel.npy\n",
            "process npy: 212 data/snake.npy\n",
            "process npy: 213 data/sea_turtle.npy\n",
            "process npy: 214 data/keyboard.npy\n",
            "process npy: 215 data/castle.npy\n",
            "process npy: 216 data/bottlecap.npy\n",
            "process npy: 217 data/mug.npy\n",
            "process npy: 218 data/baseball.npy\n",
            "process npy: 219 data/spider.npy\n",
            "process npy: 220 data/cell_phone.npy\n",
            "process npy: 221 data/jacket.npy\n",
            "process npy: 222 data/blackberry.npy\n",
            "process npy: 223 data/cactus.npy\n",
            "process npy: 224 data/frog.npy\n",
            "process npy: 225 data/potato.npy\n",
            "process npy: 226 data/lightning.npy\n",
            "process npy: 227 data/map.npy\n",
            "process npy: 228 data/violin.npy\n",
            "process npy: 229 data/giraffe.npy\n",
            "process npy: 230 data/belt.npy\n",
            "process npy: 231 data/camera.npy\n",
            "process npy: 232 data/parrot.npy\n",
            "process npy: 233 data/calendar.npy\n",
            "process npy: 234 data/campfire.npy\n",
            "process npy: 235 data/toothbrush.npy\n",
            "process npy: 236 data/fish.npy\n",
            "process npy: 237 data/paper_clip.npy\n",
            "process npy: 238 data/banana.npy\n",
            "process npy: 239 data/brain.npy\n",
            "process npy: 240 data/goatee.npy\n",
            "process npy: 241 data/trombone.npy\n",
            "process npy: 242 data/ceiling_fan.npy\n",
            "process npy: 243 data/clarinet.npy\n",
            "process npy: 244 data/lighthouse.npy\n",
            "process npy: 245 data/elbow.npy\n",
            "process npy: 246 data/camouflage.npy\n",
            "process npy: 247 data/apple.npy\n",
            "process npy: 248 data/swan.npy\n",
            "process npy: 249 data/leg.npy\n",
            "process npy: 250 data/rain.npy\n",
            "process npy: 251 data/crown.npy\n",
            "process npy: 252 data/remote_control.npy\n",
            "process npy: 253 data/pig.npy\n",
            "process npy: 254 data/sweater.npy\n",
            "process npy: 255 data/microwave.npy\n",
            "process npy: 256 data/cow.npy\n",
            "process npy: 257 data/broom.npy\n",
            "process npy: 258 data/umbrella.npy\n",
            "process npy: 259 data/school_bus.npy\n",
            "process npy: 260 data/knife.npy\n",
            "process npy: 261 data/penguin.npy\n",
            "process npy: 262 data/windmill.npy\n",
            "process npy: 263 data/clock.npy\n",
            "process npy: 264 data/sandwich.npy\n",
            "process npy: 265 data/The_Mona_Lisa.npy\n",
            "process npy: 266 data/donut.npy\n",
            "process npy: 267 data/blueberry.npy\n",
            "process npy: 268 data/dumbbell.npy\n",
            "process npy: 269 data/flamingo.npy\n",
            "process npy: 270 data/bicycle.npy\n",
            "process npy: 271 data/shorts.npy\n",
            "process npy: 272 data/rollerskates.npy\n",
            "process npy: 273 data/saxophone.npy\n",
            "process npy: 274 data/aircraft_carrier.npy\n",
            "process npy: 275 data/drill.npy\n",
            "process npy: 276 data/wristwatch.npy\n",
            "process npy: 277 data/finger.npy\n",
            "process npy: 278 data/beard.npy\n",
            "process npy: 279 data/church.npy\n",
            "process npy: 280 data/garden.npy\n",
            "process npy: 281 data/hat.npy\n",
            "process npy: 282 data/mouth.npy\n",
            "process npy: 283 data/megaphone.npy\n",
            "process npy: 284 data/stitches.npy\n",
            "process npy: 285 data/snorkel.npy\n",
            "process npy: 286 data/spoon.npy\n",
            "process npy: 287 data/tennis_racquet.npy\n",
            "process npy: 288 data/bed.npy\n",
            "process npy: 289 data/skyscraper.npy\n",
            "process npy: 290 data/purse.npy\n",
            "process npy: 291 data/screwdriver.npy\n",
            "process npy: 292 data/hamburger.npy\n",
            "process npy: 293 data/pillow.npy\n",
            "process npy: 294 data/sailboat.npy\n",
            "process npy: 295 data/light_bulb.npy\n",
            "process npy: 296 data/picture_frame.npy\n",
            "process npy: 297 data/basket.npy\n",
            "process npy: 298 data/cooler.npy\n",
            "process npy: 299 data/pencil.npy\n",
            "process npy: 300 data/kangaroo.npy\n",
            "process npy: 301 data/cruise_ship.npy\n",
            "process npy: 302 data/bulldozer.npy\n",
            "process npy: 303 data/shark.npy\n",
            "process npy: 304 data/bird.npy\n",
            "process npy: 305 data/sink.npy\n",
            "process npy: 306 data/saw.npy\n",
            "process npy: 307 data/key.npy\n",
            "process npy: 308 data/ladder.npy\n",
            "process npy: 309 data/face.npy\n",
            "process npy: 310 data/sword.npy\n",
            "process npy: 311 data/toe.npy\n",
            "process npy: 312 data/smiley_face.npy\n",
            "process npy: 313 data/motorbike.npy\n",
            "process npy: 314 data/hedgehog.npy\n",
            "process npy: 315 data/yoga.npy\n",
            "process npy: 316 data/cello.npy\n",
            "process npy: 317 data/moustache.npy\n",
            "process npy: 318 data/compass.npy\n",
            "process npy: 319 data/cloud.npy\n",
            "process npy: 320 data/house_plant.npy\n",
            "process npy: 321 data/ear.npy\n",
            "process npy: 322 data/steak.npy\n",
            "process npy: 323 data/moon.npy\n",
            "process npy: 324 data/couch.npy\n",
            "process npy: 325 data/bucket.npy\n",
            "process npy: 326 data/rainbow.npy\n",
            "process npy: 327 data/sock.npy\n",
            "process npy: 328 data/lobster.npy\n",
            "process npy: 329 data/peas.npy\n",
            "process npy: 330 data/squirrel.npy\n",
            "process npy: 331 data/stereo.npy\n",
            "process npy: 332 data/snowman.npy\n",
            "process npy: 333 data/mushroom.npy\n",
            "process npy: 334 data/boomerang.npy\n",
            "process npy: 335 data/tiger.npy\n",
            "process npy: 336 data/waterslide.npy\n",
            "process npy: 337 data/stop_sign.npy\n",
            "process npy: 338 data/dog.npy\n",
            "process npy: 339 data/snowflake.npy\n",
            "process npy: 340 data/bread.npy\n",
            "process npy: 341 data/bracelet.npy\n",
            "process npy: 342 data/snail.npy\n",
            "process npy: 343 data/headphones.npy\n",
            "process npy: 344 data/onion.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6o30ipBPAQ5Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load the Data "
      ]
    },
    {
      "metadata": {
        "id": "UBq3GXEKAYuO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Each class contains different number samples of arrays stored as .npy format. Since we have some memory limitations we only load 5000 images per class.  "
      ]
    },
    {
      "metadata": {
        "id": "6HEIgQNHYQnl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_data(root, vfold_ratio=0.2, max_items_per_class= 2000 ):\n",
        "    all_files = glob.glob(os.path.join(root, '*.npy'))\n",
        "\n",
        "    #initialize variables \n",
        "    x = np.empty([0, 784])\n",
        "    y = np.empty([0])\n",
        "    class_names = []\n",
        "\n",
        "    #load each data file \n",
        "    for idx, file in enumerate(all_files):\n",
        "        print(idx,file)\n",
        "        data = np.load(file)\n",
        "        data = data[0: max_items_per_class, :]\n",
        "        labels = np.full(data.shape[0], idx)\n",
        "\n",
        "        x = np.concatenate((x, data), axis=0)\n",
        "        y = np.append(y, labels)\n",
        "\n",
        "        class_name, ext = os.path.splitext(os.path.basename(file))\n",
        "        class_names.append(class_name)\n",
        "\n",
        "    data = None\n",
        "    labels = None\n",
        "    \n",
        "    #randomize the dataset \n",
        "    permutation = np.random.permutation(y.shape[0])\n",
        "    x = x[permutation, :]\n",
        "    y = y[permutation]\n",
        "\n",
        "    #separate into training and testing \n",
        "    vfold_size = int(x.shape[0]/100*(vfold_ratio*100))\n",
        "\n",
        "    x_test = x[0:vfold_size, :]\n",
        "    y_test = y[0:vfold_size]\n",
        "\n",
        "    x_train = x[vfold_size:x.shape[0], :]\n",
        "    y_train = y[vfold_size:y.shape[0]]\n",
        "    return x_train, y_train, x_test, y_test, class_names\n",
        "  \n",
        "  def load_data_process(root, vfold_ratio=0.2, data_process_num):\n",
        "    all_files = glob.glob(os.path.join(root, '*1.npy'))\n",
        "\n",
        "    #initialize variables \n",
        "    x = np.empty([0, 784])\n",
        "    y = np.empty([0])\n",
        "    class_names = []\n",
        "\n",
        "    #load each data file \n",
        "    for idx, file in enumerate(all_files):\n",
        "        print(idx,file)\n",
        "        data = np.load(file)\n",
        "        labels = np.full(data.shape[0], idx)\n",
        "        x = np.concatenate((x, data), axis=0)\n",
        "        y = np.append(y, labels)\n",
        "\n",
        "        class_name, ext = os.path.splitext(os.path.basename(file))\n",
        "        class_names.append(class_name)\n",
        "\n",
        "    data = None\n",
        "    labels = None\n",
        "    \n",
        "    #randomize the dataset \n",
        "    permutation = np.random.permutation(y.shape[0])\n",
        "    x = x[permutation, :]\n",
        "    y = y[permutation]\n",
        "\n",
        "    #separate into training and testing \n",
        "    vfold_size = int(x.shape[0]/100*(vfold_ratio*100))\n",
        "\n",
        "    x_test = x[0:vfold_size, :]\n",
        "    y_test = y[0:vfold_size]\n",
        "\n",
        "    x_train = x[vfold_size:x.shape[0], :]\n",
        "    y_train = y[vfold_size:y.shape[0]]\n",
        "    return x_train, y_train, x_test, y_test, class_names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K6uUjN-WL2Y9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        },
        "outputId": "c4439a0d-4644-4644-f0c7-bd9012f5cd40"
      },
      "cell_type": "code",
      "source": [
        "x_train, y_train, x_test, y_test, class_names = load_data('data')\n",
        "num_classes = len(class_names)\n",
        "image_size = 28"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 data/hot_tub.npy\n",
            "1 data/underwear.npy\n",
            "2 data/flashlight.npy\n",
            "3 data/ice_cream.npy\n",
            "4 data/watermelon.npy\n",
            "5 data/shovel.npy\n",
            "6 data/passport.npy\n",
            "7 data/necklace.npy\n",
            "8 data/train.npy\n",
            "9 data/bathtub.npy\n",
            "10 data/square.npy\n",
            "11 data/baseball_bat.npy\n",
            "12 data/panda.npy\n",
            "13 data/spreadsheet.npy\n",
            "14 data/floor_lamp.npy\n",
            "15 data/ocean.npy\n",
            "16 data/scorpion.npy\n",
            "17 data/skull.npy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-ae6971a817d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimage_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-42cefe49540f>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(root, vfold_ratio, max_items_per_class)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "VhGEDS0SMgLK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(len(x_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rNZmQvBWBBHE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Show some random data "
      ]
    },
    {
      "metadata": {
        "id": "KfpDaHRkyMQC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "%matplotlib inline  \n",
        "idx = randint(0, len(x_train))\n",
        "plt.imshow(x_train[idx].reshape(28,28)) \n",
        "print(class_names[int(y_train[idx].item())])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n8InHz5NBFrV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Preprocess the Data "
      ]
    },
    {
      "metadata": {
        "id": "p2GHUq7D2r9e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Reshape and normalize\n",
        "x_train = x_train.reshape(x_train.shape[0], image_size, image_size, 1).astype('float32')\n",
        "x_test = x_test.reshape(x_test.shape[0], image_size, image_size, 1).astype('float32')\n",
        "\n",
        "x_train /= 255.0\n",
        "x_test /= 255.0\n",
        "\n",
        "# Convert class vectors to class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rL6XAb4hBMSc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# The Model "
      ]
    },
    {
      "metadata": {
        "id": "uYUVV2wf2z8H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define model\n",
        "model = keras.Sequential()\n",
        "model.add(layers.Convolution2D(16, (3, 3),\n",
        "                        padding='same',\n",
        "                        input_shape=x_train.shape[1:], activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Convolution2D(32, (3, 3), padding='same', activation= 'relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Convolution2D(64, (3, 3), padding='same', activation= 'relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size =(2,2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(num_classes, activation='softmax')) \n",
        "# Train model\n",
        "adam = tf.train.AdamOptimizer()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=adam,\n",
        "              metrics=['top_k_categorical_accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8XZ5ZvxtxITx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_YRSRkOyBP1P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training "
      ]
    },
    {
      "metadata": {
        "id": "7OMEJ7kF3lsP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fit(x = x_train, y = y_train, validation_split=0.1, batch_size = 256, verbose=2, epochs=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d2KztY7qEn9_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Testing "
      ]
    },
    {
      "metadata": {
        "id": "ssaZczS7DxeA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test accuarcy: {:0.2f}%'.format(score[1] * 100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9xBM_w0VBbNr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Inference "
      ]
    },
    {
      "metadata": {
        "id": "nH3JfoiYHdpk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "%matplotlib inline  \n",
        "idx = randint(0, len(x_test))\n",
        "img = x_test[idx]\n",
        "plt.imshow(img.squeeze()) \n",
        "pred = model.predict(np.expand_dims(img, axis=0))[0]\n",
        "ind = (-pred).argsort()[:5]\n",
        "latex = [class_names[x] for x in ind]\n",
        "print(latex)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YPp5D82YBhM-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Store the classes "
      ]
    },
    {
      "metadata": {
        "id": "NoFI1msFYpCN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('class_names.txt', 'w') as file_handler:\n",
        "    for item in class_names:\n",
        "        file_handler.write(\"{}\\n\".format(item))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mfJ6dpaDBpRx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Install TensorFlowJS"
      ]
    },
    {
      "metadata": {
        "id": "hJJDfp9mY9Xh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorflowjs "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-oBl0ZKVB00d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Save and Convert "
      ]
    },
    {
      "metadata": {
        "id": "XVICB3TbZGb2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save('keras.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bTWWlGdWZOvs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir model\n",
        "!tensorflowjs_converter --input_format keras keras.h5 model/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JKYxE2MEB6LV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Zip and Download "
      ]
    },
    {
      "metadata": {
        "id": "865-t79uaB63",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp class_names.txt model/class_names.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GLC-MzW8ZXTa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!zip -r model.zip model "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4vfPR03xZZeD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('model.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}